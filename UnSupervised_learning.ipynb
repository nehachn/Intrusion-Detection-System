{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UnSupervised learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q2t2d1xSvC8"
      },
      "source": [
        "#Unsupervised Learning\r\n",
        "Implementing unsupervised learning algorithm as described in the given research paper https://arxiv.org/abs/2009.02930\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axMwflNm2KZY"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from collections import Counter"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOJQZgXo2LpG"
      },
      "source": [
        "df = pd.read_csv(\"SWaT_Dataset_Attack_v0.csv\")\r\n",
        "print(head)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QKhec_q2M8A"
      },
      "source": [
        "cols = df.columns\r\n",
        "# convert normal and attack innto binary variable\r\n",
        "df['Normal/Attack'].replace('Normal', 0, inplace=True)\r\n",
        "df['Normal/Attack'].replace('Attack', 1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6tqd1o2Owg"
      },
      "source": [
        "df['Normal/Attack'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7b9yLf0XykJ"
      },
      "source": [
        "df.drop(' Timestamp', axis = 1, inplace=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDTWcqNV2Ved"
      },
      "source": [
        "train_y = df['Normal/Attack']\r\n",
        "X_df = df.iloc[:, :-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHnUJTi6Eqgv",
        "outputId": "cd0b1623-01f8-4b26-a786-a8be78ea1b1a"
      },
      "source": [
        "Counter(train_y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 395298, 1: 54621})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MZ57G-dLKbr",
        "outputId": "6e9bc425-6515-4bc9-9f4f-26ccd2ef14c6"
      },
      "source": [
        "X_df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(449919, 51)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21NtDojMvfwr"
      },
      "source": [
        "#Robust Principal Component Analysis\r\n",
        "Function for RPCA. The approach used is from the paper https://arxiv.org/pdf/0912.3599.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aWAlmZ2veMK"
      },
      "source": [
        "from __future__ import division, print_function\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "try:\r\n",
        "    # Python 2: 'xrange' is the iterative version\r\n",
        "    range = xrange\r\n",
        "except NameError:\r\n",
        "    # Python 3: 'range' is iterative - no need for 'xrange'\r\n",
        "    pass\r\n",
        "\r\n",
        "\r\n",
        "class R_pca:\r\n",
        "\r\n",
        "    def __init__(self, D, mu=None, lmbda=None):\r\n",
        "        self.D = D\r\n",
        "        self.S = np.zeros(self.D.shape)\r\n",
        "        self.Y = np.zeros(self.D.shape)\r\n",
        "\r\n",
        "        if mu:\r\n",
        "            self.mu = mu\r\n",
        "        else:\r\n",
        "            self.mu = np.prod(self.D.shape) / (4 * np.linalg.norm(self.D, ord=1))\r\n",
        "\r\n",
        "        self.mu_inv = 1 / self.mu\r\n",
        "\r\n",
        "        if lmbda:\r\n",
        "            self.lmbda = lmbda\r\n",
        "        else:\r\n",
        "            self.lmbda = 1 / np.sqrt(np.max(self.D.shape))\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def frobenius_norm(M):\r\n",
        "        return np.linalg.norm(M, ord='fro')\r\n",
        "\r\n",
        "    @staticmethod\r\n",
        "    def shrink(M, tau):\r\n",
        "        return np.sign(M) * np.maximum((np.abs(M) - tau), np.zeros(M.shape))\r\n",
        "\r\n",
        "    def svd_threshold(self, M, tau):\r\n",
        "        U, S, V = np.linalg.svd(M, full_matrices=False)\r\n",
        "        return np.dot(U, np.dot(np.diag(self.shrink(S, tau)), V))\r\n",
        "\r\n",
        "    def fit(self, tol=None, max_iter=1000, iter_print=100):\r\n",
        "        iter = 0\r\n",
        "        err = np.Inf\r\n",
        "        Sk = self.S\r\n",
        "        Yk = self.Y\r\n",
        "        Lk = np.zeros(self.D.shape)\r\n",
        "\r\n",
        "        if tol:\r\n",
        "            _tol = tol\r\n",
        "        else:\r\n",
        "            _tol = 1E-7 * self.frobenius_norm(self.D)\r\n",
        "\r\n",
        "        #this loop implements the principal component pursuit (PCP) algorithm\r\n",
        "        #located in the table on page 29 of https://arxiv.org/pdf/0912.3599.pdf\r\n",
        "        while (err > _tol) and iter < max_iter:\r\n",
        "            Lk = self.svd_threshold(\r\n",
        "                self.D - Sk + self.mu_inv * Yk, self.mu_inv)                            #this line implements step 3\r\n",
        "            Sk = self.shrink(\r\n",
        "                self.D - Lk + (self.mu_inv * Yk), self.mu_inv * self.lmbda)             #this line implements step 4\r\n",
        "            Yk = Yk + self.mu * (self.D - Lk - Sk)                                      #this line implements step 5\r\n",
        "            err = self.frobenius_norm(self.D - Lk - Sk)\r\n",
        "            iter += 1\r\n",
        "            if (iter % iter_print) == 0 or iter == 1 or iter > max_iter or err <= _tol:\r\n",
        "                print('iteration: {0}, error: {1}'.format(iter, err))\r\n",
        "\r\n",
        "        self.L = Lk\r\n",
        "        self.S = Sk\r\n",
        "        return Lk, Sk\r\n",
        "\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AvKY5w7veRP",
        "outputId": "a7aac9cc-15b1-4f31-d5bd-0c4bba694261"
      },
      "source": [
        "rpca = R_pca(X_df)\r\n",
        "L, S = rpca.fit(max_iter=2500, iter_print=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration: 1, error: 204.87398230969433\n",
            "iteration: 100, error: 4.4069446695116845\n",
            "iteration: 200, error: 2.454558499167473\n",
            "iteration: 300, error: 1.38108625652243\n",
            "iteration: 400, error: 1.0897614919917433\n",
            "iteration: 500, error: 0.8263113661332471\n",
            "iteration: 600, error: 0.663239193398805\n",
            "iteration: 700, error: 0.6684110349925311\n",
            "iteration: 800, error: 0.5125580228057208\n",
            "iteration: 900, error: 0.5041732790895694\n",
            "iteration: 1000, error: 0.4630132919911478\n",
            "iteration: 1100, error: 0.42947625480114604\n",
            "iteration: 1200, error: 0.38970317472346605\n",
            "iteration: 1300, error: 0.39871112698171923\n",
            "iteration: 1400, error: 0.3556460150549144\n",
            "iteration: 1500, error: 0.3452249318968497\n",
            "iteration: 1600, error: 0.35634241564469127\n",
            "iteration: 1700, error: 0.3452141982039736\n",
            "iteration: 1800, error: 0.3330211313131723\n",
            "iteration: 1900, error: 0.34358468132297\n",
            "iteration: 2000, error: 0.342936556294922\n",
            "iteration: 2100, error: 0.34845534127559147\n",
            "iteration: 2200, error: 0.3589305149826752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxs1kMF_veWz"
      },
      "source": [
        "# the noise matrix\r\n",
        "S"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-WqUvhCx1QE"
      },
      "source": [
        "S.to_csv('S_matrix.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuyDoUbjwVKW"
      },
      "source": [
        "# the low rank matrix of M\r\n",
        "L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TQ-38NUxlMs"
      },
      "source": [
        "save('L_matrix.npy', L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqiroj8uwXT-"
      },
      "source": [
        "L.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOral0NfbqZ"
      },
      "source": [
        "Function to get the orthogonal basis vector of the low rank matrix L"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft-siUYrwiD8"
      },
      "source": [
        "\r\n",
        "def gram_schmidt(A):\r\n",
        "    \"\"\"Orthogonalize a set of vectors stored as the columns of matrix A.\"\"\"\r\n",
        "    # Get the number of vectors.\r\n",
        "    n = A.shape[1]\r\n",
        "    for j in range(n):\r\n",
        "        # To orthogonalize the vector in column j with respect to the\r\n",
        "        # previous vectors, subtract from it its projection onto\r\n",
        "        # each of the previous vectors.\r\n",
        "        for k in range(j):\r\n",
        "            A[:, j] -= np.dot(A[:, k], A[:, j]) * A[:, k]\r\n",
        "        A[:, j] = A[:, j] / np.linalg.norm(A[:, j])\r\n",
        "    return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmao-bIZwj6o"
      },
      "source": [
        "A = gram_schmidt(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHI5jd80wlKM"
      },
      "source": [
        "#set of orthogonal basis vector spaning the space S of the normal state of the system\r\n",
        "A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKvsdKM6zHV4"
      },
      "source": [
        "save('A_matrix.npy', A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4y_1UIKf0ty"
      },
      "source": [
        "Projecting the dataset on to the lowdimension subspace S"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGFm7UWtwnBO"
      },
      "source": [
        "Proj_x = A@A.T@X_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSzavyxJgCwB"
      },
      "source": [
        "Calculating the Geometric median of the the projected points as they will capture the behaviour of the stable system "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQJocv3swpvo"
      },
      "source": [
        "from scipy.spatial.distance import cdist, euclidean\r\n",
        "\r\n",
        "def geometric_median(X, eps=1e-5):\r\n",
        "    y = np.mean(X, 0)\r\n",
        "\r\n",
        "    while True:\r\n",
        "        D = cdist(X, [y])\r\n",
        "        nonzeros = (D != 0)[:, 0]\r\n",
        "\r\n",
        "        Dinv = 1 / D[nonzeros]\r\n",
        "        Dinvs = np.sum(Dinv)\r\n",
        "        W = Dinv / Dinvs\r\n",
        "        T = np.sum(W * X[nonzeros], 0)\r\n",
        "\r\n",
        "        num_zeros = len(X) - np.sum(nonzeros)\r\n",
        "        if num_zeros == 0:\r\n",
        "            y1 = T\r\n",
        "        elif num_zeros == len(X):\r\n",
        "            return y\r\n",
        "        else:\r\n",
        "            R = (T - y) * Dinvs\r\n",
        "            r = np.linalg.norm(R)\r\n",
        "            rinv = 0 if r == 0 else num_zeros/r\r\n",
        "            y1 = max(0, 1-rinv)*T + min(1, rinv)*y\r\n",
        "\r\n",
        "        if euclidean(y, y1) < eps:\r\n",
        "            return y1\r\n",
        "\r\n",
        "        y = y1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2eN9CTHzVBw"
      },
      "source": [
        "m = geometric_median(Proj_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhipasVRzXSS"
      },
      "source": [
        "m.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWbVaZGKza8A"
      },
      "source": [
        "save('m_vector.npy', m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ6X8bRBzbLs"
      },
      "source": [
        "L[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY6mvJx-ghSh"
      },
      "source": [
        "Calculating the Threshold value to detect anomaly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-26-rw72ghh3"
      },
      "source": [
        "min_float = float('-inf')\r\n",
        "theta = min_float\r\n",
        "for i in range(L.shape[0]):\r\n",
        "    dist = np.linalg.norm(m-L[i])\r\n",
        "    theta = max(theta,dist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42jUxFwvgxZn"
      },
      "source": [
        "Function to test new data point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8RhCs9Qgt3s"
      },
      "source": [
        "def classification_onepoint(x):\r\n",
        "    proj = A@A.T@x\r\n",
        "    score = np.linalg.norm(m-proj) #calculating distance from the geometric median\r\n",
        "\r\n",
        "    if score > theta: #comparing with the threshold value\r\n",
        "        return 0\r\n",
        "    else:\r\n",
        "        return 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}